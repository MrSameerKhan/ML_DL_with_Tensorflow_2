{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Stock Sentiment Analysis using News Headlines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The data is from Kaggle and here we have to predict whether stock price will increase or decrease based on news headlines. Date column have the date, label is 1 or 0. 1 means the stock price will increase, 0 means it will remain same or decrease. All the other columns containt the top news headlines of the day."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7dd3504c366f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '20150101']\n",
    "test = df[df['Date'] > '20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations\n",
    "data = train.iloc[:, 2:27]\n",
    "data.replace(\"[^a-zA-Z]\", \" \", regex=True, inplace=True)\n",
    "\n",
    "# renaming column names\n",
    "new_cols = [str(i) for i in range(25)]\n",
    "data.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting headlines to lowercase\n",
    "for col in new_cols:\n",
    "    data[col] = data[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the headlines to one paragraph\n",
    "headlines = []\n",
    "for row in range(0, len(data.index)):\n",
    "    headlines.append(' '.join(str(x) for x in data.iloc[row, 0:25] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "source": [
    "### Building the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "source": [
    "Let's write some utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    models = {\n",
    "        \"rf\": RandomForestClassifier(n_jobs=-1),\n",
    "        \"lr\": LogisticRegression(),\n",
    "        \"mnb\": MultinomialNB()\n",
    "    }\n",
    "\n",
    "    for model in models:\n",
    "        model = models[model]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        print(f\"Model: {model}\")\n",
    "        print(accuracy_score(y_test, predictions))\n",
    "        print(confusion_matrix(y_test, predictions))\n",
    "        print(classification_report(y_test, predictions))\n",
    "\n",
    "        print(\"=\"*100)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "### Bag of words\n",
    "Let's first start with a simple bag of words model\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement bag of words\n",
    "countvector = CountVectorizer(ngram_range=(2,2))\n",
    "X_train = countvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['Label']\n",
    "\n",
    "test_transform = []\n",
    "for row in range(0, len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row, 2:27]))\n",
    "\n",
    "X_test = countvector.transform(test_transform)\n",
    "y_test = test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "source": [
    "### TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train = tfidf.fit_transform(headlines).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = []\n",
    "for row in range(0, len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row, 2:27]))\n",
    "\n",
    "X_test = tfidf.transform(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(X_train, y_train, X_test, y_test)"
   ]
  }
 ]
}