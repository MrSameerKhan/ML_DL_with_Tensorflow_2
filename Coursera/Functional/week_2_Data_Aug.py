# %% [markdown]
# ***
# <a id="coding_tutorial_3"></a>
# ## Keras image data augmentation
# %% [markdown]
# #### Import the data
# 
# The dataset required for this tutorial can be downloaded from the following link:
# 
# https://drive.google.com/open?id=11Y43ta5gT672L3sfJFR2DvPs-ralY5Pd
# 
# You should store these files in Drive for use in this Colab notebook.

# %%
from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)


import tensorflow as tf
print(tf.__version__)


# %%
# Run this cell to connect to your Drive folder

# from google.colab import drive
# drive.mount('/content/gdrive')


# %%
import matplotlib.pyplot as plt
import numpy as np

# %% [markdown]
# #### Load the CIFAR-10 Dataset

# %%
from tensorflow.keras.datasets import cifar10


# %%
# Load the CIFAR-10 dataset

(training_features, training_labels), (test_features, test_labels) = cifar10.load_data()


# %%
# Convert the labels to a one-hot encoding

num_classes = 10

training_labels = tf.keras.utils.to_categorical(training_labels, num_classes)
test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)

# %% [markdown]
# #### Create a generator function

# %%
# Create a function that returns a data generator

def get_generator(features, labels, batch_size=1):
    for n in range(int(len(features)/batch_size)):
        yield (features[n*batch_size:(n+1)*batch_size], labels[n*batch_size:(n+1)*batch_size])


# %%
# Use the function we created to get a training data generator with a batch size of 1

training_generator = get_generator(training_features, training_labels)


# %%
# Assess the shape of the items generated by training_generator using the `next` function to yield an item.

image, label = next(training_generator)
print(image.shape)
print(label.shape)


# %%
# Test the training generator by obtaining an image using the `next` generator function, and then using imshow to plot it.
# Print the corresponding label

from matplotlib.pyplot import imshow

image, label = next(training_generator)
image_unbatched = image[0,:,:,:]
imshow(image_unbatched)
print(label)


# %%
# Reset the generator by re-running the `get_generator` function.

train_generator = get_generator(training_features, training_labels)

# %% [markdown]
# #### Create a data augmention generator

# %%
from tensorflow.keras.preprocessing.image import ImageDataGenerator


# %%
# Create a function to convert an image to monochrome

def monochrome(x):
    def func_bw(a):
        average_colour = np.mean(a)
        return [average_colour, average_colour, average_colour]
    x = np.apply_along_axis(func_bw, -1, x)
    return x


# %%
# Create an ImageDataGenerator object

image_generator = ImageDataGenerator(
          preprocessing_function=monochrome,
          rotation_range = 100,
          rescale =(1/255.0)
)

# %% [markdown]
# Check [the documentation](https://keras.io/preprocessing/image/) for the full list of image data augmentation options. 

# %%
# Create an iterable generator using the `flow` function

image_generator_iterable = image_generator.flow(training_features, training_labels, batch_size=1, shuffle= False)


# %%
# Show a sample from the generator and compare with the original

image, label = next(image_generator_iterable)
image_orig, label_orig = next(train_generator)
figs, axes = plt.subplots(1,2)
axes[0].imshow(image[0,:,:,:])
axes[0].set_title('Transformed')
axes[1].imshow(image_orig[0,:,:,:])
axes[1].set_title('Original')
plt.show()

# %% [markdown]
# #### Flow from directory

# %%
# Inspect the directory structure

train_path = 'data/flowers-recognition-split/train'
val_path = 'data/flowers-recognition-split/val'


# %%
# Create an ImageDataGenerator object

datagenerator = ImageDataGenerator(rescale=(1/255.0))


# %%
classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']


# %%
# Create a training data generator

train_generator = datagenerator.flow_from_directory(train_path, batch_size=64, classes=classes, target_size=(16,16))


# %%
# Create a validation data generator

val_generator = datagenerator.flow_from_directory(val_path, batch_size=64, classes=classes, target_size=(16,16))


# %%
# Get and display an image and label from the training generator

x = next(train_generator)
imshow(x[0][4])
print(x[1][4])


# %%
# Reset the training generator

train_generator = datagenerator.flow_from_directory(train_path, batch_size=64, classes=classes, target_size=(16,16))

# %% [markdown]
# #### Create a model to train

# %%
# Build a CNN model

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Flatten, Dense

model = tf.keras.Sequential()
model.add(Input((16,16,3)))
model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))
model.add(MaxPooling2D((4,4)))
model.add(Conv2D(8, (8, 8), padding='same', activation='relu'))
model.add(MaxPooling2D((2,2)))
model.add(Conv2D(4, (4, 4), padding='same', activation='relu'))
model.add(Flatten())
model.add(Dense(16, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(5, activation='softmax'))


# %%
# Create an optimizer object

optimizer = tf.keras.optimizers.Adam(1e-3)


# %%
# Compile the model

model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])


# %%
# Print the model summary

model.summary()

# %% [markdown]
# #### Train the model

# %%
# Calculate the training generator and test generator steps per epoch

train_steps_per_epoch = train_generator.n // train_generator.batch_size
val_steps = val_generator.n // val_generator.batch_size
print(train_steps_per_epoch, val_steps)


# %%
# Fit the model

model.fit_generator(train_generator, steps_per_epoch=train_steps_per_epoch, epochs=5)

# %% [markdown]
# #### Evaluate the model

# %%
# Evaluate the model

model.evaluate_generator(val_generator, steps=val_steps)

# %% [markdown]
# #### Predict using the generator

# %%
# Predict labels with the model

predictions = model.predict_generator(val_generator, steps=1)
