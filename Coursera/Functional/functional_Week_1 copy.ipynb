{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5-final"},"colab":{"name":"Copy of Coding Tutorial.ipynb","provenance":[{"file_id":"1KuZHLQP2Smiiwp1Rl_5vcpSEivjkiP2p","timestamp":1606327878119}],"collapsed_sections":["Vw_mtaCSKURC","m5zoXn36KURd","FCXImgxwKURi","LogIRCGRKURr","2D5WmZvkKURz","XEKAybugKUSD","9rOpqQVNKUSO","1fn43vXfKUSj","wQunv2imKUTH","lLnXno5vKUUH","hT_nP5czKUUe","gZ615uKaKUUv","yclV6KiFKUU3","cMYjnJDIKUVC"]}},"cells":[{"cell_type":"code","metadata":{"scrolled":false,"id":"teOpfw0hKUQh"},"source":["from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.3.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"2U6iIpalKUQr"},"source":["# The Keras functional API"]},{"cell_type":"markdown","metadata":{"id":"jIoR--DrKUQs"},"source":[" ## Coding tutorials\n"," #### [1. Multiple inputs and outputs](#coding_tutorial_1)\n"," #### [2. Tensors and Variables](#coding_tutorial_2)\n"," #### [3. Accessing model layers](#coding_tutorial_3)\n"," #### [4. Freezing layers](#coding_tutorial_4)"]},{"cell_type":"markdown","metadata":{"id":"qhZ0R9arKUQt"},"source":["***\n","<a id=\"coding_tutorial_1\"></a>\n","## Multiple inputs and outputs"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Atjv7GqMKUQu"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CCNmLCsKKUQy"},"source":["#### Load the acute inflammations dataset\n","\n","The `acute inflammations` was created by a medical expert as a data set to test the expert system, which will perform the presumptive diagnosis of two diseases of the urinary system. You can find out more about the dataset [here](https://archive.ics.uci.edu/ml/datasets/Acute+Inflammations).\n","\n","Attribute information:\n","\n","Inputs:\n","- Temperature of patient : 35C-42C\n","- Occurrence of nausea : yes/no\n","- Lumbar pain : yes/no\n","- Urine pushing (continuous need for urination) : yes/no\n","- Micturition pains : yes/no\n","- Burning of urethra, itch, swelling of urethra outlet : yes/no\n","\n","Outputs:\n","- decision 1: Inflammation of urinary bladder : yes/no\n","- decision 2: Nephritis of renal pelvis origin : yes/no"]},{"cell_type":"markdown","metadata":{"id":"BsE7ATcyKV7E"},"source":["#### Import the data\n","\n","The dataset required for this tutorial can be downloaded from the following link:\n","\n","https://drive.google.com/open?id=1CDPQSqpI7OjNIgOERWaI-BlQMI6vjzb9\n","\n","You should store this file in Drive for use in this Colab notebook."]},{"cell_type":"markdown","metadata":{"id":"mldOoZD-KUQ0"},"source":["#### Load the data"]},{"cell_type":"code","metadata":{"id":"uM2ETK5qKXDq"},"source":["# Run this cell to connect to your Drive folder\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"__6I4CYqKUQ1"},"source":["# Load the dataset\n","\n","from sklearn.model_selection import train_test_split\n","\n","pd_dat = pd.read_csv('data/diagnosis.csv')\n","dataset = pd_dat.values"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"-wVA5JI8KUQ5"},"source":["# Build train and test data splits\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:6], dataset[:,6:], test_size=0.33)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"K03GPQNZKUQ9"},"source":["# Assign training and testing inputs/outputs\n","\n","temp_train, nocc_train, lumbp_train, up_train, mict_train, bis_train = np.transpose(X_train)\n","temp_test, nocc_test, lumbp_test, up_test, mict_test, bis_test = np.transpose(X_test)\n","\n","inflam_train, nephr_train = Y_train[:, 0], Y_train[:, 1]\n","inflam_test, nephr_test = Y_test[:, 0], Y_test[:, 1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vw_mtaCSKURC"},"source":["#### Build the model"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Xjtuk2OmKURE"},"source":["# Build the input layers\n","\n","from tensorflow.keras import Input, layers\n","\n","shape_inputs = (1,)\n","temperature = Input(shape=shape_inputs, name=\"temp\")\n","nausea_occurence = Input(shape=shape_inputs, name=\"nocc\")\n","lumbar_pain = Input(shape=shape_inputs, name=\"lumbp\")\n","urine_pushing = Input(shape=shape_inputs, name=\"up\")\n","micturition_pains = Input(shape=shape_inputs, name=\"mict\")\n","bis = Input(shape=shape_inputs, name=\"bis\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"rJDt1D0LKURI"},"source":["# Create a list of all the inputs\n","\n","list_inputs = [temperature, nausea_occurence, lumbar_pain, urine_pushing, \n","               micturition_pains, bis]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"P41WGVnqKURM"},"source":["# Merge all input features into a single large vector\n","\n","x = layers.concatenate(list_inputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"BKZOJR-PKURR"},"source":["# Use a logistic regression classifier for disease prediction\n","\n","inflammation_pred = layers.Dense(1, activation=\"sigmoid\", name=\"inflam\")(x)\n","nephritis_pred = layers.Dense(1, activation=\"sigmoid\", name=\"nephr\")(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"M2tESqXWKURV"},"source":["# Create a list of all the outputs\n","\n","list_outputs = [inflammation_pred, nephritis_pred]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"AZFVEYX8KURZ"},"source":["# Create the model object\n","model = tf.keras.Model(inputs=list_inputs, outputs=list_outputs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5zoXn36KURd"},"source":["#### Plot the model"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"b3-_VOYiKURe"},"source":["# Display the multiple input/output model\n","\n","tf.keras.utils.plot_model(model, \"output/multi_input_output_model.png\", show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCXImgxwKURi"},"source":["#### Compile the model"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"MpGzpAeYKURn"},"source":["# Compile the model\n","\n","\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(1e-3),\n","            loss=[\"binary_crossentropy\", \"binary_crossentropy\"],\n","                metrics={\"inflam\" : [\"acc\"],\n","                    \"nephr\":[\"acc\"]},\n","                    loss_weights= [1., 0.2])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LogIRCGRKURr"},"source":["#### Fit the model "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"WVDztBCHKURs"},"source":["# Define training inputs and outputs\n","\n","inputs_train = {'temp': temp_train, 'nocc': nocc_train, 'lumbp': lumbp_train,\n","                'up': up_train, 'mict': mict_train, 'bis': bis_train}\n","\n","outputs_train = {'inflam': inflam_train, 'nephr': nephr_train}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nd9z2B7NKURw"},"source":["# Train the model\n","\n","\n","history = model.fit(inputs_train, outputs_train, epochs=1000, batch_size=128, verbose=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2D5WmZvkKURz"},"source":["#### Plot the learning curves"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6GgUOXPPKUR0"},"source":["# Plot the training accuracy\n","\n","acc_keys = [k for k in history.history.keys() if k in ('inflam_acc', 'nephr_acc')] \n","loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n","\n","for k, v in history.history.items():\n","    if k in acc_keys:\n","        plt.figure(1)\n","        plt.plot(v)\n","    else:\n","        plt.figure(2)\n","        plt.plot(v)\n","\n","plt.figure(1)\n","plt.title('Accuracy vs. epochs')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(acc_keys, loc='upper right')\n","\n","plt.figure(2)\n","plt.title('Loss vs. epochs')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(loss_keys, loc='upper right')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"gGnXQLRyKUR4"},"source":["# Evaluate the model\n","\n","\n","model.evaluate([temp_test, nocc_test, lumbp_test, up_test, mict_test, bis_test],\n","                [inflam_test, nephr_test], verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5xxvVY3KUR8"},"source":["***\n","<a id=\"coding_tutorial_2\"></a>\n","## Tensors and Variables"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"fTIe7EbMKUR9"},"source":["from tensorflow.compat.v1 import ConfigProto\n","from tensorflow.compat.v1 import InteractiveSession\n","\n","config = ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = InteractiveSession(config=config)\n","\n","import numpy as np\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XEKAybugKUSD"},"source":["#### Create Variable objects"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"PQnCI7UPKUSF"},"source":["# Create Variable objects of different type with tf.Variable\n","\n","strings = tf.Variable([\"Hello world!\"], tf.string)\n","floats  = tf.Variable([3.14159, 2.71828], tf.float64)\n","ints = tf.Variable([1, 2, 3], tf.int32)\n","complexs = tf.Variable([25.9 - 7.39j, 1.23 - 4.91j], tf.complex128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8st30T0kKUSJ"},"source":["# Initialise a Variable value\n","\n","tf.Variable(tf.constant(4.2, shape=[3,3]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9rOpqQVNKUSO"},"source":["#### Use and modify Variable values"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"BM_P9WM1KUSP"},"source":["# Use the value of a Variable\n","\n","v = tf.Variable(0.0)\n","w = v + 1  # w is a tf.Tensor which is computed based on the value of v.\n","\n","print(type(w))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZphqbA9bKUSV"},"source":["# Increment the value of a Variable\n","\n","v.assign_add(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"bUTr5IMKKUSc"},"source":["# Decrement the value of a Variable\n","\n","v.assign_sub(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fn43vXfKUSj"},"source":["#### Create Tensor objects"]},{"cell_type":"markdown","metadata":{"id":"ydXIlRLVKUSk"},"source":["Create a constant tensor and print its type as well as its shape:"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ynmKF5WBKUSn"},"source":["# Create a constant Tensor\n","\n","x = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","print(x)\n","print(\"dtype:\", x.dtype)\n","print(\"shape:\", x.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ONzNFdvBKUSw"},"source":["# Obtain the value as a numpy array\n","\n","x.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Z_coR5e_KUS1"},"source":["# Create a Tensor of type float32\n","\n","x = tf.constant([\n","            [1,2, 3],\n","            [4,5,6],\n","            [7,8,9]\n","], dtype=tf.float32)\n","print(x)\n","print(\"dtype : \" , x.dtype)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"66vsJ2nDKUS6"},"source":["# Create coefficients\n","\n","coeffs = np.arange(16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oklUSgBkKUS_"},"source":["# Initialise shapes\n","\n","shape1= [8,2]\n","shape2= [4,4]\n","shape3= [2,2,2,2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDueGPOZKUTE"},"source":["# Create Tensors of different shape\n","\n","a = tf.constant(coeffs, shape=shape1)\n","print(\"\\n a:\\n \", a)\n","\n","b = tf.constant(coeffs, shape=shape2)\n","print(\"\\n b:\\n \", b)\n","\n","c = tf.constant(coeffs, shape=shape3)\n","print(\"\\n c:\\n \", c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wQunv2imKUTH"},"source":["#### Useful Tensor operations"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ckoPBCdeKUTI"},"source":["# Create a constant Tensor\n","\n","t = tf.constant(np.arange(80), shape=[5,2,8])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIgKN6x_KUTN"},"source":["# Get the rank of a Tensor\n","\n","rank = tf.rank(t)\n","print(\"rank: \", rank)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1lcPqXbKUTU"},"source":["# Display the rank\n","\n","print(\"rank: \", rank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"bDZTFUpKKUTY"},"source":["# Reshape a Tensor\n","\n","t2 = tf.reshape(t, [8,10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Jh0xAmhKUTb"},"source":["# Display the new shape\n","\n","print(\"t2.shape: \", t2.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"LLGauT00KUTd"},"source":["# Create ones, zeros, identity and constant Tensors\n","\n","ones = tf.ones(shape=(2,3))\n","zeros = tf.zeros(shape=(2,4))\n","eye = tf.eye(3)\n","tensor7  = tf.constant(7.0, shape=[2,2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rqVS1qx7KUTf"},"source":["# Display the created tensors\n","\n","print(\"\\n Ones:\\n \", ones)\n","print(\"\\n Zeros:\\n \", zeros)\n","print(\"\\n Identity:\\n \", eye)\n","print(\"\\n Tensor filled with 7: \", tensor7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"HWrvSDxNKUTl"},"source":["# Create a ones Tensor and a zeros Tensor\n","\n","t1 = tf.ones(shape=(2, 2))\n","t2 = tf.zeros(shape=(2, 2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"1j_bYOrhKUTq"},"source":["# Concatentate two Tensors\n","\n","concat0 = tf.concat([t1,t2], 0)\n","concat1 = tf.concat([t1,t2], 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtbFujr7KUTt"},"source":["# Display the concatenated tensors\n","\n","print(concat0)\n","print(concat1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"M-WVtu8DKUTw"},"source":["# Create a constant Tensor\n","\n","t = tf.constant(np.arange(24), shape=(3, 2, 4))\n","print(\"\\n t shape: \", t.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"RrN4aMQWKUT2"},"source":["# Expanding the rank of Tensors\n","\n","t1 = tf.expand_dims(t, 0)\n","t2 = tf.expand_dims(t, 1)\n","t3 = tf.expand_dims(t,3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"kB-r55xiKUT5"},"source":["# Display the shapes after tf.expand_dims\n","\n","print(\"\\n After expanding dims:\\n t1 shape: \", t1.shape, \"\\n t2 shape: \", t2.shape, \"\\n t3 shape: \", t3.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"q1zKORaAKUT9"},"source":["# Squeezing redundant dimensions\n","\n","t1 = tf.squeeze(t1, 0)\n","t2 = tf.squeeze(t2, 1)\n","t3 = tf.squeeze(t3, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"94Uy3Y5GKUUB"},"source":["# Display the shapes after tf.squeeze\n","\n","print(\"\\n After squeezing:\\n t1 shape: \", t1.shape, \"\\n t2 shape: \", t2.shape, \"\\n t3 shape: \", t3.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"bSnXwk3YKUUE"},"source":["# Slicing a Tensor\n","\n","x = tf.constant([1,2,3,4,5,6,7])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lLnXno5vKUUH"},"source":["#### Doing maths with Tensors"]},{"cell_type":"code","metadata":{"id":"8cvyLI90KUUH"},"source":["# Create two constant Tensors\n","\n","c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n","d = tf.constant([[1.0, 1.0], [0.0, 1.0]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"zOr2CRcYKUUM"},"source":["# Matrix multiplication\n","\n","matmul_cd = tf.matmul(c,d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlBvG6UxKUUP"},"source":["# Display the result\n","\n","print(\"\\n tf.matmul(c,d):\\n\", matmul_cd)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"lMJMXHoMKUUR"},"source":["# Elementwise operations\n","\n","c_times_d = c*d\n","c_plus_d = c+d\n","c_minus_d = c-d\n","c_div_c = c/c"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eoHiulOKUUT"},"source":["# Display the results\n","\n","print(\"\\n c*d:\\n\", c_times_d)\n","print(\"\\n c+d:\\n\", c_plus_d)\n","print(\"\\n c-d:\\n\", c_minus_d)\n","print(\"\\n c/c:\\n\", c_div_c)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"UTjk8RmQKUUV"},"source":["# Create Tensors\n","\n","a = tf.constant([[2, 3], [3, 3]])\n","b = tf.constant([[8, 7], [2, 3]])\n","x = tf.constant([[-6.89 + 1.78j], [-2.54 + 2.15j]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fKpXUAWKUUY"},"source":["# Absolute value of a Tensor\n","\n","absx = tf.abs(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_slSXaBKUUa"},"source":["# Power of a Tensor\n","\n","powaa = tf.pow(a, a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"-XlewNGEKUUc"},"source":["# Display the results\n","\n","print(\"\\n \", absx)\n","print(\"\\n \", powaa)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hT_nP5czKUUe"},"source":["#### Randomly sampled constant tensors"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"BCYaFEZpKUUe"},"source":["# Create a Tensor with samples from a Normal distribution\n","\n","tn = tf.random.normal(shape=[2,2], mean=0, stddev=1.)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"TQuZhEUjKUUi"},"source":["# Create a Tensor with samples from a Uniform distribution\n","\n","tu = tf.random.uniform(shape=[2,1], minval=0, maxval=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"XJfvSj97KUUo"},"source":["# Create a Tensor with samples from a Poisson distribution\n","\n","tp = tf.random.poisson((2,2), 5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"CdHl0f_AKUUq"},"source":["# More maths operations\n","\n","d = tf.square(tn)\n","e = tf.exp(d)\n","f = tf.cos(c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_y5iM-XKUUs"},"source":["***\n","<a id=\"coding_tutorial_3\"></a>\n","## Accessing model layers"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"x-XwASmfKUUt"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from tensorflow.keras.applications import VGG19\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZ615uKaKUUv"},"source":["#### Load the pre-trained model"]},{"cell_type":"markdown","metadata":{"id":"ZEnVLPANKUUv"},"source":["In this section, we aim to demonstrate accessing layer attributes within a model.\n","\n","Let's get started by loading the `VGG19` pre-trained model from the `keras.applications` library, which is a very deep network trained on more than a million images from the ImageNet database. The network is trained to classify images into 1000 object categories."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"_4qCBLtSKUUw"},"source":["# Load the VGG19 model\n","\n","vgg_model = VGG19()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zFI6-6oJKUUy"},"source":["# Get the inputs, layers and display the summary\n","\n","vgg_input = vgg_model.input\n","vgg_layers = vgg_model.layers\n","vgg_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yclV6KiFKUU3"},"source":["#### Build a model to access the layer outputs"]},{"cell_type":"code","metadata":{"id":"Cov4lXwdKUU4"},"source":["from tensorflow.keras.models import Model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"aQsJZr1YKUU6"},"source":["# Build a model that returns the layer outputs\n","\n","layer_outputs = [layer.output for layer in vgg_layers]\n","features = Model(inputs=vgg_input, outputs=layer_outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"78R_lcAwKUU7"},"source":["# Plot the model\n","\n","tf.keras.utils.plot_model(features, \"output/vgg19_model.png\", show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"j35hgDZZKUU9"},"source":["# Test the model on a random input\n","\n","img = np.random.random((1,224,224,3)).astype(\"float32\")\n","extracted_features = features(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ogh9UxE8KUU_"},"source":["#### Load the 'cool cat' picture"]},{"cell_type":"markdown","metadata":{"id":"BUxx2lk0KUU_"},"source":["In Zambia’s South Luangwa National Park, a photographer had been watching a pride of lions while they slept off a feast from a buffalo kill. When this female walked away, he anticipated that she might be going for a drink and so he positioned his vehicle on the opposite side of the waterhole. The `cool cat` picture is one of the highly commended 2018 Image from Wildlife Photographer of the Year."]},{"cell_type":"markdown","metadata":{"id":"rWLD97iOK5ut"},"source":["#### Import the picture\n","\n","The dataset required for this tutorial can be downloaded from the following link:\n","\n","https://drive.google.com/open?id=1myXpP8QFvhATqg0bPYhCpVS48_OgAC0L\n","\n","You should store this file in Drive for use in this Colab notebook."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ylT-Kt65KUVA"},"source":["# Display the original image\n","\n","import IPython.display as display\n","from PIL import Image\n","\n","display.display(Image.open('data/cool_cat.jpg'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cMYjnJDIKUVC"},"source":["#### Visualise network features from the input image"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"96Z1V9XsKUVD"},"source":["# Preprocess the image\n","\n","from tensorflow.keras.applications.vgg19 import preprocess_input\n","from tensorflow.keras.preprocessing import image\n","\n","img_path = 'data/cool_cat.jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Bg74WXDCKUVF"},"source":["# Extract the features\n","\n","extracted_features = features(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"eR_e_HmmKUVH"},"source":["# Visualise the input channels\n","\n","f1 = extracted_features[0]\n","print(\"\\n f1.shape: \", f1.shape)\n","\n","imgs = f1[0,:,:]\n","plt.figure(figsize=(15,15))\n","for n in range(3):\n","    ax = plt.subplot(1,3,n+1)\n","    plt.imshow(imgs[:,:,n])\n","    plt.axis(\"off\")\n","plt.subplots_adjust(wspace=0.01, hspace=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Ke-6Vpj3KUVI"},"source":["# Visualise some features in the first hidden layer\n","\n","f2 = extracted_features[1]\n","print(\"\\n f2.shape: \", f2.shape)\n","\n","imgs = f2[0,:,:]\n","plt.figure(figsize=(15,15))\n","for n in range(16):\n","    ax = plt.subplot(4,4,n+1)\n","    plt.imshow(imgs[:,:,n])\n","    plt.axis(\"off\")\n","plt.subplots_adjust(wspace=0.01, hspace=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"eTV70KvoKUVK"},"source":["# Build a model to extract features by layer name\n","\n","extracted_features_block1_pool = Model(inputs=features.input, outputs=features.get_layer(\"block1_pool\").output)\n","block1_pool_features = extracted_features_block1_pool.predict(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"WQvb0OuUKUVM"},"source":["# Visualise some features from the extracted layer output\n","\n","imgs = block1_pool_features[0,:,:]\n","plt.figure(figsize=(15,15))\n","for n in range(16):\n","    ax = plt.subplot(4,4,n+1)\n","    plt.imshow(imgs[:,:,n])\n","    plt.axis(\"off\")\n","plt.subplots_adjust(wspace=0.01, hspace=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"We6poZ7dKUVP"},"source":["# Extract features from a layer deeper in the network\n","\n","extracted_features_block5_conv4 = Model(inputs=features.input, outputs=features.get_layer(\"block5_conv4\").output)\n","block5_conv4_features = extracted_features_block5_conv4.predict(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"8hOJSdVQKUVR"},"source":["# Visualise some features from the extracted layer output\n","\n","imgs = block5_conv4_features[0,:,:]\n","plt.figure(figsize=(15,15))\n","for n in range(16):\n","    ax = plt.subplot(4,4,n+1)\n","    plt.imshow(imgs[:,:,n])\n","    plt.axis(\"off\")\n","plt.subplots_adjust(wspace=0.01, hspace=0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FV766ybKUVS"},"source":["***\n","<a id=\"coding_tutorial_4\"></a>\n","## Freezing layers"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"qvMmt0s5KUVS"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"muJ3y73wKUVU"},"source":["#### Build the model"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"a7XUKYHpKUVU"},"source":["# Build a small Sequential model\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","\n","model = Sequential([\n","    layers.Dense(4, input_shape=(4,), activation='relu', kernel_initializer='random_uniform',\n","                 bias_initializer='ones'),\n","    layers.Dense(2, activation='relu', kernel_initializer='lecun_normal', bias_initializer='ones'),\n","    layers.Dense(4, activation='softmax'),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"cl9gvwc_KUVV"},"source":["# Display the model summary\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_weights(model):\n","    return [e.weights[0].numpy() for e in model.layers]\n","\n","def get_biases(model):\n","    return [e.bias.numpy() for e in model.layers]\n","\n","def plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers):\n","    plt.figure(figsize=(8,8))\n","    for n in range(3):\n","        delta_l = W1_layers[n] - W0_layers[n]\n","        print('Layer '+str(n)+': bias variation: ', np.linalg.norm(b1_layers[n] - b0_layers[n]))\n","        ax = plt.subplot(1,3,n+1)\n","        plt.imshow(delta_l)\n","        plt.title('Layer '+str(n))\n","        plt.axis('off')\n","    plt.colorbar()\n","    plt.suptitle('Weight matrices variation');\n","    "]},{"cell_type":"markdown","metadata":{"id":"oLZVUklBKUVX"},"source":["#### Examine the weight matrix variation over training"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"kLSwnr6IKUVX"},"source":["# Retrieve the weights and biases\n","\n","W0_layers = get_weights(model)\n","b0_layers = get_biases(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"vpxvNkMnKUVa"},"source":["# Construct a synthetic dataset\n","\n","x_train = np.random.random((100, 4))\n","y_train = x_train\n","\n","x_test = np.random.random((20, 4))\n","y_test = x_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"ZTNGzE9-KUVc"},"source":["# Compile and fit the model\n","\n","model.compile(optimizer='adam',\n","              loss='mse',\n","              metrics=['acc'])\n","\n","model.fit(x_train, y_train, epochs=50, verbose=False);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"jjY6rOOkKUVd"},"source":["# Retrieve weights and biases\n","\n","W1_layers = get_weights(model)\n","b1_layers = get_biases(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"1ZDHstynKUVe"},"source":["# Plot the variation\n","\n","plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hrhsfqdwKUVg"},"source":["#### Freeze layers at build time"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"xlxrMUF5KUVg"},"source":["# Count the trainable and non trainable variables before the freezing\n","\n","n_trainable_variables = len(model.trainable_variables)\n","n_non_trainable_variables = len(model.non_trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNpfvfSXKUVi"},"source":["# Display the number of trainable and non trainable variables before the freezing\n","\n","print(\"\\n Before freezing:\\n\\t Number of trainable variables: \", n_trainable_variables,\n","                         \"\\n\\t Number of non trainable variables: \", n_non_trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"AGpSC4ZAKUVn"},"source":["# Build the model\n","\n","model = Sequential([\n","    layers.Dense(4, input_shape=(4,), activation='relu', kernel_initializer='random_uniform',\n","                 bias_initializer='ones', trainable = False),\n","    layers.Dense(2, activation='relu', kernel_initializer='lecun_normal', bias_initializer='ones'),\n","    layers.Dense(4, activation='softmax'),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"lWmPkL-pKUVo"},"source":["# Count the trainable and non trainable variables after the freezing\n","\n","n_trainable_variables = len(model.trainable_variables)\n","n_non_trainable_variables = len(model.non_trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Bzhnsr7KUVp"},"source":["# Display the number of trainable and non trainable variables after the freezing\n","\n","print(\"\\n After freezing:\\n\\t Number of trainable variables: \", n_trainable_variables,\n","                         \"\\n\\t Number of non trainable variables: \", n_non_trainable_variables)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Kl6-nIeYKUVr"},"source":["# Retrieve weights and biases\n","\n","W0_layers = get_weights(model)\n","b0_layers = get_biases(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"aoOhSvdCKUVs"},"source":["# Compile and fit the model\n","\n","model.compile(optimizer='adam',\n","              loss='mse',\n","              metrics=['acc'])\n","\n","model.fit(x_train, y_train, epochs=50, verbose=False);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"VW2Ij7rGKUVt"},"source":["# Retrieve weights and biases\n","\n","W1_layers = get_weights(model)\n","b1_layers = get_biases(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"SJv_yc34KUVv"},"source":["# Plot the variation\n","\n","plot_delta_weights(W0_layers, W1_layers, b0_layers, b1_layers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FkbrhuxUKUVw"},"source":["#### Freeze layers of a pre-built model"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"1EuSNnI1KUVx"},"source":["# Count the trainable and non trainable variables before the freezing\n","\n","print(\"\\n Before freezing:\\n\\t Number of trainable variables: \", len(model.trainable_variables),\n","                         \"\\n\\t Number of non trainable variables: \", len(model.non_trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"xKISfPTaKUVz"},"source":["# Freeze the second layer\n","\n","model.layers[1].trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"lS1xI65tKUV0"},"source":["# Count the trainable and non trainable variables after the freezing\n","\n","print(\"\\n After freezing:\\n\\t Number of trainable variables: \", len(model.trainable_variables),\n","                        \"\\n\\t Number of non trainable variables: \", len(model.non_trainable_variables))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"e0yk7ZZoKUV3"},"source":["# Compile and fit the model\n","\n","model.compile(optimizer='adam',\n","              loss='mse',\n","              metrics=['acc'])\n","\n","model.fit(x_train, y_train, epochs=50, verbose=False);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"2nlvj0k-KUV4"},"source":["# Retrieve weights and biases\n","\n","W2_layers = get_weights(model)\n","b2_layers = get_biases(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"O7LO4ZWvKUV5"},"source":["# Plot the variation\n","\n","plot_delta_weights(W1_layers, W2_layers, b1_layers, b2_layers)"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}